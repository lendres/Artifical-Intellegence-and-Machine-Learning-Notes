\noindent {}Figure{} \hfill Page\vspace *{\lofskip }\endgraf 
\addvspace {10\p@ }
\addvspace {\chapterstyleblofskip }
\contentsline {figure}{\numberline {1.1}{\ignorespaces Normal distribution}}{2}{figure.caption.5}%
\contentsline {figure}{\numberline {1.2}{\ignorespaces Levels versus factors for ANOVA}}{5}{figure.caption.6}%
\contentsline {figure}{\numberline {1.3}{\ignorespaces Hypothesis testing errors}}{6}{figure.caption.7}%
\contentsline {figure}{\numberline {1.4}{\ignorespaces Hypothesis test matrix}}{6}{figure.caption.8}%
\contentsline {figure}{\numberline {1.5}{\ignorespaces Hypothesis test flow chart}}{9}{figure.caption.9}%
\addvspace {10\p@ }
\addvspace {\chapterstyleblofskip }
\addvspace {10\p@ }
\addvspace {\chapterstyleblofskip }
\addvspace {10\p@ }
\addvspace {\chapterstyleblofskip }
\addvspace {10\p@ }
\addvspace {\chapterstyleblofskip }
\addvspace {10\p@ }
\addvspace {\chapterstyleblofskip }
\contentsline {figure}{\numberline {6.1}{\ignorespaces Cross validation}}{35}{figure.caption.17}%
\contentsline {figure}{\numberline {6.2}{\ignorespaces Over and under sampling}}{35}{figure.caption.18}%
\contentsline {figure}{\numberline {6.3}{\ignorespaces Model coefficients}}{36}{figure.caption.19}%
\contentsline {figure}{\numberline {6.4}{\ignorespaces Linear versus ridge regression}}{37}{figure.caption.20}%
\contentsline {figure}{\numberline {6.5}{\ignorespaces Ridge versus Lasso regression}}{38}{figure.caption.21}%
\addvspace {10\p@ }
\addvspace {\chapterstyleblofskip }
\contentsline {figure}{\numberline {7.1}{\ignorespaces Pipeline building}}{41}{figure.caption.22}%
\contentsline {figure}{\numberline {7.2}{\ignorespaces GridSearchCV}}{43}{figure.caption.23}%
\contentsline {figure}{\numberline {7.3}{\ignorespaces RandomSearchCV}}{44}{figure.caption.24}%
\addvspace {10\p@ }
\addvspace {\chapterstyleblofskip }
\contentsline {figure}{\numberline {8.1}{\ignorespaces Connectivity base clustering dendrogram}}{47}{figure.caption.25}%
\contentsline {figure}{\numberline {8.2}{\ignorespaces Distance measures between clusters}}{48}{figure.caption.26}%
\contentsline {figure}{\numberline {8.3}{\ignorespaces K-means clustering}}{50}{figure.caption.27}%
\contentsline {figure}{\numberline {8.4}{\ignorespaces Elbow method of finding the optimum number of clusters}}{51}{figure.caption.29}%
\contentsline {figure}{\numberline {8.5}{\ignorespaces Clustering visualization}}{52}{figure.caption.30}%
\contentsline {figure}{\numberline {8.6}{\ignorespaces Hierarchical clustering}}{55}{figure.caption.31}%
\contentsline {figure}{\numberline {8.7}{\ignorespaces Principal component analysis}}{57}{figure.caption.32}%
\contentsline {figure}{\numberline {8.8}{\ignorespaces Eigenvalues and fraction of variation explained}}{57}{figure.caption.33}%
\contentsline {figure}{\numberline {8.9}{\ignorespaces Dimensionality reduction with t-SNE}}{58}{figure.caption.34}%
\contentsline {figure}{\numberline {8.10}{\ignorespaces Perplexity values}}{59}{figure.caption.35}%
\contentsline {figure}{\numberline {8.11}{\ignorespaces Example of t-SNE}}{60}{figure.caption.37}%
\addvspace {10\p@ }
\addvspace {\chapterstyleblofskip }
\contentsline {figure}{\numberline {9.1}{\ignorespaces Artificial neural networks versus linear regression}}{61}{figure.caption.38}%
\contentsline {figure}{\numberline {9.2}{\ignorespaces Introduction to regression and artificial neural networks}}{61}{figure.caption.39}%
\contentsline {figure}{\numberline {9.3}{\ignorespaces Introduction to classification and artificial neural network}}{62}{figure.caption.40}%
\contentsline {figure}{\numberline {9.4}{\ignorespaces Classification and artificial neural network}}{62}{figure.caption.41}%
\contentsline {figure}{\numberline {9.5}{\ignorespaces Tensor ranks}}{62}{figure.caption.42}%
\contentsline {figure}{\numberline {9.6}{\ignorespaces Introduction to tensor operations}}{63}{figure.caption.43}%
\contentsline {figure}{\numberline {9.7}{\ignorespaces First attempt at artificial neural network}}{63}{figure.caption.44}%
\contentsline {figure}{\numberline {9.8}{\ignorespaces Example 1 of the linear relationship of perceptron}}{63}{figure.caption.45}%
\contentsline {figure}{\numberline {9.9}{\ignorespaces Example 2 of the linear relationship of perceptron}}{64}{figure.caption.46}%
\contentsline {figure}{\numberline {9.10}{\ignorespaces Adding a hidden layer to a neural network}}{64}{figure.caption.47}%
\contentsline {figure}{\numberline {9.11}{\ignorespaces Multiple nodes in a hidden layer}}{65}{figure.caption.48}%
\contentsline {figure}{\numberline {9.12}{\ignorespaces Multiple hidden layers}}{65}{figure.caption.49}%
\contentsline {figure}{\numberline {9.13}{\ignorespaces Deep learning and reduction in error percentage}}{65}{figure.caption.50}%
\contentsline {figure}{\numberline {9.14}{\ignorespaces Growth of hidden layers}}{66}{figure.caption.51}%
\contentsline {figure}{\numberline {9.15}{\ignorespaces The Sigmoid activation function}}{66}{figure.caption.52}%
\contentsline {figure}{\numberline {9.16}{\ignorespaces The Softmax activation function}}{66}{figure.caption.53}%
\contentsline {figure}{\numberline {9.17}{\ignorespaces The ReLu activation function}}{66}{figure.caption.54}%
\contentsline {figure}{\numberline {9.18}{\ignorespaces Activation functions on hidden layers}}{67}{figure.caption.55}%
\contentsline {figure}{\numberline {9.19}{\ignorespaces Popular activation functions}}{67}{figure.caption.56}%
\contentsline {figure}{\numberline {9.20}{\ignorespaces Weights and biases}}{67}{figure.caption.57}%
\contentsline {figure}{\numberline {9.21}{\ignorespaces Gradient descent step 1}}{67}{figure.caption.58}%
\contentsline {figure}{\numberline {9.22}{\ignorespaces Gradient descent step 2}}{68}{figure.caption.59}%
\contentsline {figure}{\numberline {9.23}{\ignorespaces Gradient descent step 3}}{68}{figure.caption.60}%
\contentsline {figure}{\numberline {9.24}{\ignorespaces Gradient descent step 4}}{68}{figure.caption.61}%
\contentsline {figure}{\numberline {9.25}{\ignorespaces Calculating the gradient step 1}}{69}{figure.caption.62}%
\contentsline {figure}{\numberline {9.26}{\ignorespaces Calculating the gradient step 2}}{69}{figure.caption.63}%
\contentsline {figure}{\numberline {9.27}{\ignorespaces Calculating the gradient step 3}}{69}{figure.caption.64}%
\contentsline {figure}{\numberline {9.28}{\ignorespaces Calculating the gradient step 4}}{69}{figure.caption.65}%
\contentsline {figure}{\numberline {9.29}{\ignorespaces Calculating the gradient step 5}}{70}{figure.caption.66}%
\contentsline {figure}{\numberline {9.30}{\ignorespaces Batch size in gradient descent}}{70}{figure.caption.68}%
\contentsline {figure}{\numberline {9.31}{\ignorespaces Normalization for neural networks}}{70}{figure.caption.69}%
\contentsline {figure}{\numberline {9.32}{\ignorespaces Number of hidden layers hyperparameter for neural networks}}{70}{figure.caption.70}%
\contentsline {figure}{\numberline {9.33}{\ignorespaces Number of neurons hyperparameter for neural networks}}{71}{figure.caption.71}%
\contentsline {figure}{\numberline {9.34}{\ignorespaces Activation functions hyperparameter for neural networks}}{71}{figure.caption.72}%
\contentsline {figure}{\numberline {9.35}{\ignorespaces Gradient descent hyperparameters for neural networks}}{71}{figure.caption.73}%
\contentsline {figure}{\numberline {9.36}{\ignorespaces Inter layer hyperparameters for neural networks}}{71}{figure.caption.74}%
\contentsline {figure}{\numberline {9.37}{\ignorespaces Algorithm for tuning artificial neural networks}}{71}{figure.caption.75}%
\addvspace {10\p@ }
\addvspace {\chapterstyleblofskip }
\contentsline {figure}{\numberline {10.1}{\ignorespaces Machine learning versus deep learning}}{74}{figure.caption.77}%
\contentsline {figure}{\numberline {10.2}{\ignorespaces Using Google Colab step 1}}{75}{figure.caption.78}%
\contentsline {figure}{\numberline {10.3}{\ignorespaces Using Google Colab step 2}}{75}{figure.caption.79}%
\contentsline {figure}{\numberline {10.4}{\ignorespaces Using Google Colab step 3}}{75}{figure.caption.80}%
\contentsline {figure}{\numberline {10.5}{\ignorespaces Using Google Colab step 4}}{75}{figure.caption.81}%
\contentsline {figure}{\numberline {10.6}{\ignorespaces Using Google Colab step 5}}{76}{figure.caption.82}%
\contentsline {figure}{\numberline {10.7}{\ignorespaces Biological versus artificial neuron}}{77}{figure.caption.83}%
\contentsline {figure}{\numberline {10.8}{\ignorespaces Boolean gates}}{77}{figure.caption.84}%
\contentsline {figure}{\numberline {10.9}{\ignorespaces Rosenblatt perceptron}}{78}{figure.caption.85}%
\contentsline {figure}{\numberline {10.10}{\ignorespaces Perceptron learning algorithm part 1}}{80}{figure.caption.86}%
\contentsline {figure}{\numberline {10.11}{\ignorespaces Perceptron learning algorithm part 2}}{80}{figure.caption.87}%
\contentsline {figure}{\numberline {10.12}{\ignorespaces Artificial neural network}}{82}{figure.caption.89}%
\contentsline {figure}{\numberline {10.13}{\ignorespaces Fully connected artificial neural network part 1}}{83}{figure.caption.90}%
\contentsline {figure}{\numberline {10.14}{\ignorespaces Fully connected artificial neural network part 2}}{83}{figure.caption.91}%
\contentsline {figure}{\numberline {10.15}{\ignorespaces Fully connected artificial neural network part 3}}{84}{figure.caption.92}%
\contentsline {figure}{\numberline {10.16}{\ignorespaces Fully connected artificial neural network part 4}}{84}{figure.caption.93}%
\contentsline {figure}{\numberline {10.17}{\ignorespaces Fully connected artificial neural network part 5}}{85}{figure.caption.94}%
\contentsline {figure}{\numberline {10.18}{\ignorespaces Fully connected artificial neural network part 6}}{85}{figure.caption.95}%
\contentsline {figure}{\numberline {10.19}{\ignorespaces Artificial neural network classification}}{86}{figure.caption.96}%
\contentsline {figure}{\numberline {10.20}{\ignorespaces Regression in artificial neural networks}}{86}{figure.caption.97}%
\contentsline {figure}{\numberline {10.21}{\ignorespaces Node connectivity}}{87}{figure.caption.98}%
\contentsline {figure}{\numberline {10.22}{\ignorespaces Table of activation functions}}{88}{figure.caption.99}%
\contentsline {figure}{\numberline {10.23}{\ignorespaces Activation functions comparison}}{88}{figure.caption.100}%
\contentsline {figure}{\numberline {10.24}{\ignorespaces ReLU versus linear activation function}}{89}{figure.caption.101}%
\contentsline {figure}{\numberline {10.25}{\ignorespaces Softmax activation function}}{90}{figure.caption.102}%
\contentsline {figure}{\numberline {10.26}{\ignorespaces Activation functions and Cover's theorem}}{90}{figure.caption.103}%
\contentsline {figure}{\numberline {10.27}{\ignorespaces Neurons stretch features to achieve Cover's theorem}}{91}{figure.caption.104}%
\contentsline {figure}{\numberline {10.28}{\ignorespaces Forward propagation}}{92}{figure.caption.105}%
\contentsline {figure}{\numberline {10.29}{\ignorespaces Forward propagation bias term}}{92}{figure.caption.106}%
\contentsline {figure}{\numberline {10.30}{\ignorespaces Loss versus accuracy}}{93}{figure.caption.107}%
\contentsline {figure}{\numberline {10.31}{\ignorespaces Convex versus non-convex loss function}}{94}{figure.caption.108}%
\contentsline {figure}{\numberline {10.32}{\ignorespaces Non-convex loss in 3D}}{94}{figure.caption.109}%
\contentsline {figure}{\numberline {10.33}{\ignorespaces Loss functions}}{95}{figure.caption.110}%
\contentsline {figure}{\numberline {10.34}{\ignorespaces Mean square error}}{95}{figure.caption.111}%
\contentsline {figure}{\numberline {10.35}{\ignorespaces Mean absolute error}}{96}{figure.caption.112}%
\contentsline {figure}{\numberline {10.36}{\ignorespaces Mean absolute error}}{96}{figure.caption.113}%
\contentsline {figure}{\numberline {10.37}{\ignorespaces Back propagation}}{97}{figure.caption.114}%
\contentsline {figure}{\numberline {10.38}{\ignorespaces Gradient descent learning rate}}{99}{figure.caption.115}%
\contentsline {figure}{\numberline {10.39}{\ignorespaces Convex error function}}{99}{figure.caption.116}%
\contentsline {figure}{\numberline {10.40}{\ignorespaces Actual versus predicted values}}{99}{figure.caption.117}%
\contentsline {figure}{\numberline {10.41}{\ignorespaces Gradient descent update equation}}{100}{figure.caption.118}%
\contentsline {figure}{\numberline {10.42}{\ignorespaces Gradient descent quantum of error}}{101}{figure.caption.119}%
\contentsline {figure}{\numberline {10.43}{\ignorespaces Gradient descent new weight and bias}}{101}{figure.caption.120}%
\addvspace {10\p@ }
\addvspace {\chapterstyleblofskip }
\contentsline {figure}{\numberline {11.1}{\ignorespaces Local minimums of a non-convex function}}{103}{figure.caption.121}%
\contentsline {figure}{\numberline {11.2}{\ignorespaces Saddle point}}{103}{figure.caption.122}%
\contentsline {figure}{\numberline {11.3}{\ignorespaces Stochastic gradient descent}}{104}{figure.caption.123}%
\contentsline {figure}{\numberline {11.4}{\ignorespaces Stochastic gradient descent with momentum}}{105}{figure.caption.124}%
\contentsline {figure}{\numberline {11.5}{\ignorespaces Root mean square propagation equations}}{106}{figure.caption.125}%
\contentsline {figure}{\numberline {11.6}{\ignorespaces Weight initialization for neural networks}}{109}{figure.caption.126}%
\contentsline {figure}{\numberline {11.7}{\ignorespaces Vanishing and exploding gradients}}{110}{figure.caption.127}%
\contentsline {figure}{\numberline {11.8}{\ignorespaces Neural network weight initialization}}{110}{figure.caption.128}%
\contentsline {figure}{\numberline {11.9}{\ignorespaces Xavier normal initialization}}{111}{figure.caption.129}%
\contentsline {figure}{\numberline {11.10}{\ignorespaces Xavier uniform initialization}}{111}{figure.caption.129}%
\contentsline {figure}{\numberline {11.11}{\ignorespaces HE normal initialization}}{111}{figure.caption.130}%
\contentsline {figure}{\numberline {11.12}{\ignorespaces HE uniform initialization}}{111}{figure.caption.130}%
\contentsline {figure}{\numberline {11.13}{\ignorespaces Over fitting in neural networks}}{112}{figure.caption.132}%
\contentsline {figure}{\numberline {11.14}{\ignorespaces Use of drop out to prevent over fitting}}{113}{figure.caption.133}%
\contentsline {figure}{\numberline {11.15}{\ignorespaces Preventing over fitting by stopping when testing error starts increasing}}{113}{figure.caption.134}%
\contentsline {figure}{\numberline {11.16}{\ignorespaces Before and after applying drop out in a neural network}}{115}{figure.caption.135}%
\contentsline {figure}{\numberline {11.17}{\ignorespaces Batch normalization of hidden layers}}{116}{figure.caption.136}%
\contentsline {figure}{\numberline {11.18}{\ignorespaces Batch normalization and activation functions}}{117}{figure.caption.137}%
\contentsline {figure}{\numberline {11.19}{\ignorespaces Batch normalization of deep layers}}{118}{figure.caption.138}%
\contentsline {figure}{\numberline {11.20}{\ignorespaces Learning rates in neural networks}}{120}{figure.caption.139}%
\contentsline {figure}{\numberline {11.21}{\ignorespaces Loss curve in neural networks}}{120}{figure.caption.140}%
\addvspace {10\p@ }
\addvspace {\chapterstyleblofskip }
\addvspace {10\p@ }
\addvspace {\chapterstyleblofskip }
\contentsline {figure}{\numberline {13.1}{\ignorespaces Feature extraction}}{123}{figure.caption.141}%
\contentsline {figure}{\numberline {13.2}{\ignorespaces Image of a brick used for convolution example}}{125}{figure.caption.143}%
\contentsline {figure}{\numberline {13.3}{\ignorespaces Convolution vertical and horizontal edge detection}}{125}{figure.caption.144}%
\contentsline {figure}{\numberline {13.4}{\ignorespaces Edge detection step 1}}{127}{figure.caption.145}%
\contentsline {figure}{\numberline {13.5}{\ignorespaces Edge detection step 2}}{127}{figure.caption.146}%
\contentsline {figure}{\numberline {13.6}{\ignorespaces Edge detection step 3}}{127}{figure.caption.147}%
\contentsline {figure}{\numberline {13.7}{\ignorespaces Edge detection example}}{128}{figure.caption.148}%
\contentsline {figure}{\numberline {13.8}{\ignorespaces Image convoluted with a filter to produce a feature map.\relax }}{128}{figure.caption.149}%
\contentsline {figure}{\numberline {13.9}{\ignorespaces Edge detection steps, part 1.\relax }}{130}{figure.caption.150}%
\contentsline {figure}{\numberline {13.10}{\ignorespaces Edge detection steps, part 2.\relax }}{131}{figure.caption.151}%
\contentsline {figure}{\numberline {13.11}{\ignorespaces Prewitt filter}}{132}{figure.caption.152}%
\contentsline {figure}{\numberline {13.12}{\ignorespaces Prewitt filter example}}{132}{figure.caption.153}%
\contentsline {figure}{\numberline {13.13}{\ignorespaces Sobel filter}}{133}{figure.caption.154}%
\contentsline {figure}{\numberline {13.14}{\ignorespaces Sobel filter example}}{133}{figure.caption.155}%
\contentsline {figure}{\numberline {13.15}{\ignorespaces Laplacian filter}}{133}{figure.caption.156}%
\contentsline {figure}{\numberline {13.16}{\ignorespaces Laplacian filter example}}{134}{figure.caption.157}%
\contentsline {figure}{\numberline {13.17}{\ignorespaces Convolution on RGB images}}{134}{figure.caption.158}%
\contentsline {figure}{\numberline {13.18}{\ignorespaces Convolution with multiple filters}}{134}{figure.caption.159}%
\contentsline {figure}{\numberline {13.19}{\ignorespaces Convolution weights are treated as learnable parameters}}{135}{figure.caption.160}%
\contentsline {figure}{\numberline {13.20}{\ignorespaces Convolution under utilizes edge pixels}}{136}{figure.caption.161}%
\contentsline {figure}{\numberline {13.21}{\ignorespaces Convolution without padding shrinks the matrix}}{137}{figure.caption.162}%
\contentsline {figure}{\numberline {13.22}{\ignorespaces Using padding prevents matrix shrinking}}{137}{figure.caption.163}%
\contentsline {figure}{\numberline {13.23}{\ignorespaces Valid padding}}{138}{figure.caption.164}%
\contentsline {figure}{\numberline {13.24}{\ignorespaces Same padding}}{138}{figure.caption.165}%
\contentsline {figure}{\numberline {13.25}{\ignorespaces Stride}}{138}{figure.caption.166}%
\contentsline {figure}{\numberline {13.26}{\ignorespaces Max pooling}}{139}{figure.caption.168}%
\contentsline {figure}{\numberline {13.27}{\ignorespaces Average pooling}}{140}{figure.caption.169}%
\contentsline {figure}{\numberline {13.28}{\ignorespaces Flattening a 3D array}}{141}{figure.caption.171}%
\addvspace {10\p@ }
\addvspace {\chapterstyleblofskip }
\contentsline {figure}{\numberline {14.1}{\ignorespaces Cross validation}}{143}{figure.caption.172}%
\contentsline {figure}{\numberline {14.2}{\ignorespaces Loading a TensorFlow image data set}}{143}{figure.caption.173}%
\contentsline {figure}{\numberline {14.3}{\ignorespaces Numpy array loading of image data set}}{144}{figure.caption.174}%
\contentsline {figure}{\numberline {14.4}{\ignorespaces Image broken down into RGB channels}}{145}{figure.caption.175}%
\contentsline {figure}{\numberline {14.5}{\ignorespaces Image processing with ANNs}}{146}{figure.caption.176}%
\contentsline {figure}{\numberline {14.6}{\ignorespaces Expense of image processing with ANNs}}{146}{figure.caption.177}%
\contentsline {figure}{\numberline {14.7}{\ignorespaces Translational invariance for CNNs}}{147}{figure.caption.178}%
\contentsline {figure}{\numberline {14.8}{\ignorespaces CNNs ignore background}}{148}{figure.caption.179}%
\contentsline {figure}{\numberline {14.9}{\ignorespaces CNNs features}}{148}{figure.caption.180}%
\contentsline {figure}{\numberline {14.10}{\ignorespaces CNNs architecture}}{149}{figure.caption.181}%
\contentsline {figure}{\numberline {14.11}{\ignorespaces CNN feature extraction}}{149}{figure.caption.182}%
\contentsline {figure}{\numberline {14.12}{\ignorespaces CNN convolution}}{150}{figure.caption.183}%
\contentsline {figure}{\numberline {14.13}{\ignorespaces CNN activation function}}{150}{figure.caption.184}%
\contentsline {figure}{\numberline {14.14}{\ignorespaces Flattening pooled features maps to an array}}{151}{figure.caption.185}%
\contentsline {figure}{\numberline {14.15}{\ignorespaces CNN basic example}}{152}{figure.caption.186}%
\contentsline {figure}{\numberline {14.16}{\ignorespaces Convolution neural network}}{153}{figure.caption.187}%
\contentsline {figure}{\numberline {14.17}{\ignorespaces Types of pooling}}{153}{figure.caption.188}%
\contentsline {figure}{\numberline {14.18}{\ignorespaces Padding and stride in CNNs}}{154}{figure.caption.189}%
\addvspace {10\p@ }
\addvspace {\chapterstyleblofskip }
\addvspace {10\p@ }
\addvspace {\chapterstyleblofskip }
\contentsline {figure}{\numberline {B.1}{\ignorespaces Enable nbextensions for Jupyter notebooks}}{175}{figure.caption.190}%
